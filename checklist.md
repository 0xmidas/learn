# AI/PyTorch Learning Checklist

## Fundamentals
- [x] MLP
- [x] ReLU activation
- [x] Training loop
- [x] Evaluation loop

## CNN Fundamentals
- [x] Conv2d implementation (naive nested loops)
- [x] MaxPool2d implementation
- [x] Basic CNN architecture (conv → relu → pool)
- [x] Train on MNIST
- [ ] im2col efficient convolution
- [ ] Batch normalization
- [ ] Residual/skip connections
- [ ] Depthwise separable convolutions
- [ ] Transposed convolutions
- [ ] Global average pooling

## Classic Architectures
- [x] Simple ConvNet (LeNet-style)
- [ ] AlexNet
- [ ] VGG
- [ ] ResNet
- [ ] Inception

## Sequence Models
- [ ] RNN
- [ ] LSTM
- [ ] GRU

## Attention & Transformers
- [ ] Attention mechanism
- [ ] Self-attention
- [ ] Transformer encoder
- [ ] Transformer decoder
- [ ] Vision Transformer (ViT)

